receivers:
  # Receive OTLP from our application
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Use the filelog receiver to read the application's logs from its log file.
  # This config reads JSON logs in same format that the Cloud Logging agents
  # support:
  # https://cloud.google.com/logging/docs/structured-logging#special-payload-fields
  filelog:
    start_at: beginning
    include:
    - "/var/log/app.log"
    operators:
      - type: json_parser
        parse_to: body
        timestamp:
          parse_from: body.timestamp
          layout: '%Y-%m-%dT%H:%M:%S.%fZ'
        severity:
          parse_from: body.severity
          preset: none
          # parse minimal set of severity strings that Cloud Logging explicitly supports
          # https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#LogSeverity
          mapping:
            debug: debug
            info: info
            info3: notice
            warn: warning
            error: error
            fatal: critical
            fatal3: alert
            fatal4: emergency

      # set trace_flags to SAMPLED if GCP attribute is set to true
      - type: add
        field: body.trace_flags
        value: "01"
        if: body["logging.googleapis.com/trace_sampled"] == true

      # parse the trace context fields from GCP attributes
      - type: regex_parser
        parse_from: body["logging.googleapis.com/trace"]
        parse_to: body
        regex: (?P<trace_id>.*)
        trace:
          span_id:
            parse_from: body["logging.googleapis.com/spanId"]

      # Remove fields that are redundant from translation above and already
      # included in OTel LogEntry message
      - type: remove
        field: body.timestamp
      - type: remove
        field: body.trace_id
      - type: remove
        field: body.trace_flags
      - type: remove
        field: body.severity
      - type: remove
        field: body["logging.googleapis.com/trace"]
      - type: remove
        field: body["logging.googleapis.com/spanId"]
      - type: remove
        field: body["logging.googleapis.com/trace_sampled"]

processors:
  # Batch telemetry together to more efficiently send to GCP
  batch:
    send_batch_max_size: 500
    send_batch_size: 500
    timeout: 5s
  # Drop metrics if memory usage gets too high
  memory_limiter:
    check_interval: 1s
    limit_percentage: 65
    spike_limit_percentage: 20
  # Provide defaults for Google Managed Service for Prometheus labels
  resource:
    attributes:
      - { key: "cloud.region", value: "us-central1", action: "insert" }
      - { key: "k8s.cluster.name", value: "no-cluster", action: "insert" }
      - { key: "k8s.namespace.name", value: "no-namespace", action: "insert" }
      - { key: "service.name", value: "${env:K_SERVICE}", action: "insert" } # parse service name from K_SERVICE Cloud Run variable 
      - { key: "service.instance.id", from_attribute: "faas.id", action: "upsert" } # add instance_id as a resource attribute  
  # If running on GCP (e.g. on GKE, Cloud Run), detect resource attributes from the environment.
  resourcedetection:
    detectors: ["env", "gcp"]
    timeout: 2s
    override: false

exporters:
  # Export logs and traces using the standard googelcloud exporter
  googlecloud:
    project: ${GOOGLE_CLOUD_PROJECT}
    log:
      default_log_name: "opentelemetry.io/collector-exported-log"
  # Export metrics to Google Managed service for Prometheus
  googlemanagedprometheus:
    project: ${GOOGLE_CLOUD_PROJECT}

extensions:
  health_check:

service:
  extensions: [health_check]
  pipelines:
    traces:
      receivers: ["otlp"]
      processors: ["batch", "resourcedetection"]
      exporters: ["googlecloud"]
    metrics:
      receivers: ["otlp"]
      processors: ["batch", "memory_limiter", "resourcedetection", "resource"]
      exporters: ["googlemanagedprometheus"]
    logs:
      receivers: ["filelog"]
      processors: ["batch", "resourcedetection"]
      exporters: ["googlecloud"]